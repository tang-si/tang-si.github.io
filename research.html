
<!doctype html>
<html lang="en">
  <head>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Nian (Oakley) Liu</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-29643011-3', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- New GA4 tracking code, see https://support.google.com/analytics/answer/10271001#analyticsjs-enable-basic --> 
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GNJD50R0Z7"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-GNJD50R0Z7');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>
    
    <style>
      button.accordion {
      font:14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
      }
      button.accordion.active, button.accordion:hover {
      background-color: #f8f8f8;
      }
      button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color:#777;
      float: left;
      margin-left: 1px;
      }

      button.accordion.active:after {
      content: " [\2212] ";
      }
      div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
      }
      div.panel.show {
      display: block !important;
      }
      .social-row {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Nian (Oakley) Liu</h1>
        <p>Master of Computer Science<br>Beijing University of Posts and Telecommunications</p>
    <h3><a href="https://liun-online.github.io/">Home</a></h3>
        <h3><a href="https://liun-online.github.io/research.html">Research</a></h3>
    <h3><a href="https://liun-online.github.io/research/CV.pdf">CV</a></h3>  
        <h3><a href="https://liun-online.github.io/code.html">Code</a></h3> 
        <h3><a href="https://liun-online.github.io/teaching.html">Teaching</a></h3> 
        <h3><a href="https://liun-online.github.io/personal.html">Personal</a></h3>
    <b>Social</b><br>
        <div class="social-row">
          <a href="mailto:oakley.liun@gmail.com" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a><br>
          <a href="https://scholar.google.com/citations?user=Tx8vRjUAAAAJ&hl=en" target="_blank"><i class="ai ai-fw ai-google-scholar-square"></i> Scholar</a><br>
          <a href="https://github.com/liun-online"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
          <br>
        </div>
        <br>

    <p><b>Contact:</b><br>Department of Computer Science<br>Beijing University of Posts and Telecommunications<br>Xitucheng Road 10<br>Beijing haidian district, China</p>
    <p><b>Post</b>: 100876</p>
    <p><b>Phone</b>: +86 13041092011</p>
      </header>
      <section>

    <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Papers under Revision</h2>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="./research/extension_final.pdf">Hierarchical Contrastive Learning Enhanced Heterogeneous Graph Neural Network</a> <br> <b>Authors</b>: <b>Nian Liu</b>, <a href="https://wangxiaocs.github.io/">Xiao Wang</a>, Hui Han, <a href="http://shichuan.org/">Chuan Shi</a> <br> <b>Journal</b>: <i>IEEE Transactions on Knowledge and Data Engineering</i> <b>(TKDE)</b><br>
    <p style="text-align: center;"><img src="./research/model_heco_.PNG" height="250" width="400"></p>
    <p style="margin:0"> <b>Overview</b>: This work argues that besides cross-view contrast to capture commonality in HeCo, view-specific 
information also should be explored by intra-view contrast. </p>
    <p style="margin:0"><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Heterogeneous graph neural networks (HGNNs) as an emerging technique have shown superior capacity of dealing with
heterogeneous information network (HIN). However, most HGNNs follow a semi-supervised learning manner, which notably limits their
wide use in reality since labels are usually scarce in real applications. Recently, contrastive learning, a self-supervised method, becomes
one of the most exciting learning paradigms and shows great potential when there are no labels. In this paper, we study the problem
of self-supervised HGNNs and propose a novel co-contrastive learning mechanism for HGNNs, named HeCo. Different from traditional
contrastive learning which only focuses on contrasting positive and negative samples, HeCo employs cross-view contrastive mechanism.
Specifically, two views of a HIN (network schema and meta-path views) are proposed to learn node embeddings, so as to capture both
of local and high-order structures simultaneously. Then the cross-view contrastive learning, as well as a view mask mechanism, is
proposed, which is able to extract the positive and negative embeddings from two views. This enables the two views to collaboratively
supervise each other and finally learn high-level node embeddings. Moreover, to further boost the performance of HeCo, two additional
methods are designed to generate harder negative samples with high quality. The essence of HeCo is to make positive samples from
different views close to each other by cross-view contrast, and learn the factors invariant to two proposed views. However, besides
the invariant factors, view-specific factors complementally provide the diverse structure information between different nodes, which also
should be contained into the final embeddings. Therefore, we need to further explore each view independently and propose a modified
model, called HeCo++. Specifically, HeCo++ conducts hierarchical contrastive learning, including cross-view and intra-view contrasts,
which aims to enhance the mining of respective structures. Extensive experiments conducted on a variety of real-world networks show
the superior performance of the proposed methods over the state-of-the-arts. </p></div>
    
    <hr>

    <h2><a id="recent-papers-updated" class="anchor" href="#workingpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Working Papers</h2>
    <p style="margin:0"> Coming soon. <br> <br> 

    <hr>

    <h2><a id="published-papers-updated" class="anchor" href="#publications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Published Papers</h2>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://arxiv.org/abs/2210.02330">Revisiting Graph Contrastive Learning from the Perspective of Graph Spectrum</a> <br> <b>Authors</b>: <b>Nian Liu</b>, <a href="https://wangxiaocs.github.io/">Xiao Wang</a>, <a href="https://scholar.google.com/citations?user=m4rsQCAAAAAJ&hl=zh-CN">Deyu Bo</a>, <a href="http://shichuan.org/">Chuan Shi</a>, <a href="https://ece.duke.edu/faculty/jian-pei">Jian Pei</a><br> <b>Conference</b>: <i>Advances in neural information processing systems</i> <b>(NeurIPS)</b>, 2022<br>
    <p style="margin:0"><img src="./research/model_spco.PNG" height="200" width="500"></p>
    <p style="margin:0"> <b>Overview</b>: This is the first attempt to fundamentally explore the augmentation strategies for GCL from spectral 
domain. We not only reveal the general graph augmentation rule behind different augmentation, but also 
explain why GCL works by proposing the contrastive invariance theorem. Our work provides deeper 
understanding on the nature of GCL.</p> 
    <p style="margin:0"> <b>Code</b>: https://github.com/liun-online/SpCo</p> 
    <p style="margin:0"><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>
Graph Contrastive Learning (GCL), learning the node representations by augmenting graphs, has attracted considerable attentions. Despite the proliferation of
various graph augmentation strategies, some fundamental questions still remain
unclear: what information is essentially encoded into the learned representations
by GCL? Are there some general graph augmentation rules behind different augmentations? If so, what are they and what insights can they bring? In this paper,
we answer these questions by establishing the connection between GCL and graph
spectrum. By an experimental investigation in spectral domain, we firstly find
the General grAph augMEntation (GAME) rule for GCL, i.e., the difference of
the high-frequency parts between two augmented graphs should be larger than
that of low-frequency parts. This rule reveals the fundamental principle to revisit
the current graph augmentations and design new effective graph augmentations.
Then we theoretically prove that GCL is able to learn the invariance information
by contrastive invariance theorem, together with our GAME rule, for the first
time, we uncover that the learned representations by GCL essentially encode the
low-frequency information, which explains why GCL works. Guided by this
rule, we propose a spectral graph contrastive learning module (SpCo1
), which is
a general and GCL-friendly plug-in. We combine it with different existing GCL
models, and extensive experiments well demonstrate that it can further improve the
performances of a wide variety of different GCL methods.</p></div>
    <p style="margin:0"><button class="accordion">
      Poster
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Update soon </p></div>
    <p style="margin:0"><button class="accordion">
      Vedio
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Update soon </p></div><br>
    
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://arxiv.org/abs/2201.05540">Compact Graph Structure Learning via Mutual Information Compression</a> <br> <b>Authors</b>: <b>Nian Liu</b>, <a href="https://wangxiaocs.github.io/">Xiao Wang</a>, <a href="https://sites.google.com/a/email.wm.edu/teddy-lfwu/">Lingfei Wu</a>, <a href="http://academic.hugochan.net/">Yu Chen</a>, <a href="https://sites.google.com/view/xiaojie-guo-personal-site">Xiaojie Guo</a>, <a href="http://shichuan.org/">Chuan Shi</a><br> <b>Conference</b>: <i>International World Wide Web Conference</i> <b>(TheWebConf)</b>, 2022 <br>
    <p style="margin:0"><img src="./research/model_cogsl.png" height="200" width="500"></p>
    <p style="margin:0"> <b>Overview</b>:  In this paper, we are the first to define the “optimal graph structure” in principle by Information 
theory, which can achieve effectiveness and robustness simultaneously.</p> 
    <p style="margin:0"> <b>Code</b>: https://github.com/liun-online/CoGSL</p> 
    <p style="margin:0"><button class="accordion"> 
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>Graph Structure Learning (GSL) recently has attracted considerable
attentions in its capacity of optimizing graph structure as well as
learning suitable parameters of Graph Neural Networks (GNNs) simultaneously. Current GSL methods mainly learn an optimal graph
structure (final view) from single or multiple information sources
(basic views), however the theoretical guidance on what is the optimal graph structure is still unexplored. In essence, an optimal graph
structure should only contain the information about tasks while
compress redundant noise as much as possible, which is defined as
"minimal sufficient structure", so as to maintain the accurancy and
robustness. How to obtain such structure in a principled way? In
this paper, we theoretically prove that if we optimize basic views
and final view based on mutual information, and keep their performance on labels simultaneously, the final view will be a minimal
sufficient structure. With this guidance, we propose a Compact GSL
architecture by MI compression, named CoGSL. Specifically, two
basic views are extracted from original graph as two inputs of the
model, which are refinedly reestimated by a view estimator. Then,
we propose an adaptive technique to fuse estimated views into the
final view. Furthermore, we maintain the performance of estimated
views and the final view and reduce the mutual information of every
two views. To comprehensively evaluate the performance of CoGSL,
we conduct extensive experiments on several datasets under clean
and attacked conditions, which demonstrate the effectiveness and
robustness of CoGSL. </p></div>
    <p style="margin:0"><button class="accordion">
      Vedio
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://www.youtube.com/watch?v=cSohAhgO8Po">Online Presentation</a> </p></div><br>
    
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://arxiv.org/abs/2105.09111">Self-supervised Heterogeneous Graph Neural Network with Co-contrastive Learning</a> <br> <b>Authors</b>: <a href="https://wangxiaocs.github.io/">Xiao Wang</a>, <b>Nian Liu</b>, Hui Han, <a href="http://shichuan.org/">Chuan Shi</a> <br><b>Conference</b>: <i>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining</i> <b>(KDD)</b>, 2021<br>
    <p style="margin:0"><img src="./research/model_heco.png" height="200" width="500"></p>
    <p style="margin:0"> <b>Overview</b>:  HeCo is the first to conduct cross-view contrastive learning in heterogeneous graph. According to 
PaperDigest, this paper is one of the most influential paper in KDD 2021 as for 2022/05.</p> 
    <p style="margin:0"> <b>Code</b>: https://github.com/liun-online/HeCo</p> 
    <p style="margin:0"><button class="accordion"> 
    Abstract
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>Heterogeneous graph neural networks (HGNNs) as an emerging technique have shown superior capacity of dealing with heterogeneous information network (HIN). However, most HGNNs follow a semi-supervised learning manner, which notably limits their wide use in reality since labels are usually scarce in real applications. Recently, contrastive learning, a self-supervised method, becomes one of the most exciting learning paradigms and shows great potential when there are no labels. In this paper, we study the problem of self-supervised HGNNs and propose a novel co-contrastive learning mechanism for HGNNs, named HeCo. Different from traditional contrastive learning which only focuses on contrasting positive and negative samples, HeCo employs cross-viewcontrastive mechanism. Specifically, two views of a HIN (network schema and meta-path views) are proposed to learn node embeddings, so as to capture both of local and high-order structures simultaneously. Then the cross-view contrastive learning, as well as a view mask mechanism, is proposed, which is able to extract the positive and negative embeddings from two views. This enables the two views to collaboratively supervise each other and finally learn high-level node embeddings. Moreover, two extensions of HeCo are designed to generate harder negative samples with high quality, which further boosts the performance of HeCo. Extensive experiments conducted on a variety of real-world networks show the superior performance of the proposed methods over the state-of-the-arts.</p></div>
    <p style="margin:0"><button class="accordion">
      Poster
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="./research/poster_heco.png">Online Presentation</a></p></div>
    <p style="margin:0"><button class="accordion">
      Vedio
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://dl.acm.org/doi/10.1145/3447548.3467415">Online Presentation</a></p></div>
     <p style="margin:0"><button class="accordion">
      Slide
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="./research/slide_heco.pdf">Slide</a></p></div><br>
    
    
    <hr>

    <h2><a id="works-in-progress" class="anchor" href="#workinprogress" aria-hidden="true"><span class="octicon octicon-link"></span></a>Works in Progress</h2>

    <p style="margin:0"> <b>Beating the Heat: Temperature and Spatial Reallocation over the Long Run</b> <br> with <a href="https://www.christosmakridis.com/">Christos Makridis</a>. <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Does temperature affect real economic activity? Using the annual Current Population Survey between 1963 and 2015, we show that there is no association between temperature and earnings, hours, or output after controlling for time-invariant spatial heterogeneity and time-varying demographic factors. These results are robust to five separate sources of micro-data, different sampling horizons, functional forms, spatial measures of temperature, and subsets of the data. This paper studies the relationship between temperature and productivity across space and time. Motivated by these null results, we develop a spatial equilibrium model where temperature can affect not only firm productivity, but also individual locational choice. After calibrating the model, we use it to disentangle the role of reallocation versus actual productivity losses in the U.S. economy between 1980 and 2015. Nearly all of the variation is driven by reallocation. We subsequently use the model to evaluate a counterfactual climate scenario and recover a new spatial equilibrium for the U.S. economy by 2050. </p></div><br>

    <p style="margin:0"> <b>The Role of Supply and Demand Factors in Explaining the Migration of College Majors</b> <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>  This paper documents a new stylized fact about the United States labor market: internal migration rates are dramatically different across college majors. For some college majors, migration rates are even lower than those without a college degree. I relate major migration rates with majors' spatial concentration and find that a major's spatial concentration explains about one fourth of the cross-major variation in migration rates. With this descriptive evidence as a guide, I estimate a structural model of locational choice where college graduates have heterogeneous preferences---at the detailed major level---for living close to home, and for working in a location with a high concentration of their fellow majors. Using estimates of the structural model, I decompose the cross-major migration rates into supply and demand factors and find that supply factors (i.e. moving costs) explain the vast majority of differences in migration rates across majors. My findings underscore the difficulty in attracting college majors to a particular location using demand-side investments. My results also highlight the importance of place in determining the labor market outcomes of college majors.</p></div><br>

    <p style="margin:0"> <b>Minorities in STEM: The Role of Ability Revelation</b> <br> with <a href="http://www.nickchk.com/">Nick Huntington-Klein</a>. <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Coming soon.</p></div><br>

      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    <script> 
    var acc = document.getElementsByClassName("accordion");
    var i;

    for (i = 0; i < acc.length; i++) {
        acc[i].onclick = function(){
            this.classList.toggle("active");
            this.parentNode.nextElementSibling.classList.toggle("show");
      }
    }
    </script>
  </body>
</html>
